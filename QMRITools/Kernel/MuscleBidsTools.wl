(* ::Package:: *)

(* ::Title:: *)
(*QMRITools MuscleBidsTools*)


(* ::Subtitle:: *)
(*Written by: Martijn Froeling, PhD*)
(*m.froeling@gmail.com*)


(* ::Section:: *)
(*Begin Package*)


BeginPackage["QMRITools`MuscleBidsTools`", Join[{"Developer`"}, Complement[QMRITools`$Contexts, {"QMRITools`MuscleBidsTools`"}]]];


(* ::Section:: *)
(*Usage Notes*)


(* ::Subsection::Closed:: *)
(*Functions*)


ImportJSON::usage = 
"ImportJSON[file] impors a json file as rawJSON."

GetJSONPosition::usage = 
"GetJSONPosition[{json..}, {{key, value}..}] gets the position from a list of JSON association lists where keys have the given value.
GetJSONPosition[{json..}, {{key, value}..}, sortkey] same but finaly sorts the positions for the value of the sortkey."

MergeJSON::usage = 
"MergeJSON[{json..}] merges a list of JSON association lists where duplicate keys with same values are removed and duplicate keys with different values are merges."

AddToJson::usage = 
"AddToJson[json, <|key->value..|>] adds new keys and values to the JSON list where duplicte keys are eitehr removed or joined.
AddToJson[json, \"QMRITools\"] adds the QMRITools software version to the json."

ExtractFromJSON::usage = 
"ExtractFromJSON[keys] if the keys exist they are extracted from the json."

ViewConfig::usage = 
"ViewConfig[config] show a config file for Muscle Bids processing."

GetConfig::usage = 
"GetConfig[folder] Imports a Muscle Bids config file from the given folder."


PartitionBidsName::usage = 
"PartitionBidsName[name] converts a Bids name to the a Bids labels as an association, i.e. {\"sub\",\"ses\",\"stk\",\"rep\",\"type\",\"suf\"}."

PartitionBidsFolderName::usage = 
"PartitionBidsFolderName[fol] partitions the Bids folder and file name. it retruns the bids root folder and the label parts using PartitionBidsName."

GenerateBidsName::usage = 
"GenerateBidsName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName."

GenerateBidsFolderName::usage = 
"GenerateBidsFolderName[parts] generates a Bids folder name from the Bids labels association which can be generated by PartitionBidsFolderName."

GenerateBidsFileName::usage = 
"GenerateBidsFileName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName.
GenerateBidsFileName[fol, parts] the same but with a custom root folder."

SelectBidsFolders::usage =
"SelectBidsFolders[fol, tag] Selects all folders in the fol with the name tag."

SelectBidsSubjects::usage =
"SelectBidsSubjects[fol] selects all subjects in the bids folder."

SelectBidsSessions::usage =
"SelectBidsSessions[fol] selects all sessions in the bids subject folder."


BidsDcmToNii::usage =
"BidsDcmToNii[dir] converts the bids sourceFolder with dicom files to raw nii files based on the config file."


MuscleBidsConvert::usage =
"MuscleBidsConvert[dir] converts all raw nii data in the to Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsProcess::usage = 
"MuscleBidsProcess[dir] processes all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsMerge::usage = 
"MuscleBidsMerge[niiFol] merges multiple stack data for all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

CheckDataDiscription::usage =
"CheckDataDiscription[discription] checks the data discription config file used in BidsDcmToNii, MuscleBidsConvert, MuscleBidsProcess and MuscleBidsMerge."


(* ::Subsection::Closed:: *)
(*Options*)


BidsIncludeSession::usage = 
"BidsIncludeSession is an option for BidsDcmToNii. If True session folders will be used in output even if they are not specified."


DeleteAfterConversion::usage = 
"DeleteAfterConversion is an option for MuscleBidsConvert. If set True all files that have been converted will be deleted."

SelectSubjects::usage = 
"SelectSubjects is an option for MuscleBidsConvert. Can be a list of bids subject names else it is All."


VersionCheck::usage = 
"VersionCheck is an option for MuscleBidsProcess. If set True data processed with an old version is reprocessed."


(* ::Subsection::Closed:: *)
(*Error Messages*)


CheckDataDiscription::type = "Unknown Muscle-BIDS type: `1`, using folder \"miss\".";

CheckDataDiscription::class = "Unknown Muscle-BIDS Class: `1`. Must be \"Volume\", \"Stacks\", \"Repetitions\".";

CheckDataDiscription::lab = "Invalid combination of Class and Label: `1` with `2` is not allowed.";

CheckDataDiscription::man = "Manditory values \"Lable\" and \"Type\" are not in the data discription.";

CheckDataDiscription::stk = "Class \"stacks\" is used but overlap is not defined, assuming overlap 0.";


GetConfig::conf = "Could not find config file in given folder."


(* ::Section:: *)
(*Functions*)


Begin["`Private`"] 


(* ::Subsection:: *)
(*BIDS name and select*)


(* ::Subsubsection::Closed:: *)
(*General Definitions*)


bidsTypes = <|
	(*anata types*)
	"T1w"->"anat", "T1w-FS"->"anat", "T2w"->"anat", "T2w-FS"->"anat",
	(*dixon*)
	"megre"->"dix", "mese"->"quant",
	(*quant types*)
	"T1"->"quant", "T2"->"quant", "wT2"->"quant",
	(*diff types*)
	"dwi"->"dwi"
|>;


bidsName = {"sub", "ses", "stk", "rep", "Type", "suf"};


bidsClass = {"Volume", "Stacks", "Repetitions"};


dataToLog =If[KeyExistsQ[#, $Failed], 
	"Wrong data dicription: " <> #[$Failed], 
	StringJoin[ToString[#[[1]]] <> ": " <> ToString[#[[2]]] <> "; " & /@ Normal[KeyDrop[#, {"Process", "Merging"}]]]
]&;


(* ::Subsubsection::Closed:: *)
(*PartitionBidsName*)


SyntaxInformation[PartitionBidsName] = {"ArgumentsPattern" -> {_}};

PartitionBidsName[list_?ListQ]:=PartitionBidsName/@list

PartitionBidsName[string_?StringQ]:=Block[{parts,labs,suf},
	parts=StringSplit[#,"-"]&/@StringSplit[string,"_"];
	labs=Rule@@#&/@Select[parts,Length[#]===2&];
	suf=Flatten[Select[parts,Length[#]=!=2&]];
	suf=If[suf=!={},If[MemberQ[Keys[bidsTypes],First@suf],{"Type"->First@suf,"suf"->Rest@suf},{"suf"->suf}],{"suf"->{}}];
	Association[Join[labs,suf]]
] 


(* ::Subsubsection::Closed:: *)
(*PartitionBidsFolderName*)


SyntaxInformation[PartitionBidsFolderName] = {"ArgumentsPattern" -> {_}};

PartitionBidsFolderName[fol_?ListQ]:=PartitionBidsFolderName/@fol

PartitionBidsFolderName[fol_?StringQ]:={
	First@StringSplit[fol,"sub-"],PartitionBidsName@StringJoin@Riffle[Select[FileNameSplit[fol],StringContainsQ[#,"-"]&],"_"]
} 


(* ::Subsubsection::Closed:: *)
(*GenerateBidsName*)


SyntaxInformation[GenerateBidsName] = {"ArgumentsPattern" -> {_}};

GenerateBidsName[list_?ListQ]:=GenerateBidsName/@list

GenerateBidsName[parts_?AssociationQ]:=StringJoin[Riffle[Select[Join[
	BidsString[parts, {"sub", "ses", "stk", "rep"}], BidsValue[parts, {"Type", "suf"}
]],#=!=""&],"_"]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFolderName*)


SyntaxInformation[GenerateBidsFolderName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFolderName[fol_?StringQ, list_?ListQ]:=GenerateBidsFolderName[fol,#]&/@list

GenerateBidsFolderName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"]
},#1=!=""&]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFileName*)


SyntaxInformation[GenerateBidsFileName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFileName[list_?ListQ]:=GenerateBidsFileName["",#]&/@list

GenerateBidsFileName[fol_?StringQ, list_?ListQ]:=GenerateBidsFileName[fol,#]&/@list

GenerateBidsFileName[parts_?AssociationQ]:=GenerateBidsFileName["",parts]

GenerateBidsFileName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"], BidsType[parts], GenerateBidsName[parts]
},#1=!=""&]]


(* ::Subsubsection::Closed:: *)
(*SelectBidsFolders*)


SyntaxInformation[SelectBidsFolders] = {"ArgumentsPattern" -> {_, _}};

SelectBidsFolders[fol_?ListQ, tag_] := Flatten[SelectBidsFolders[#, tag] & /@ fol]
SelectBidsFolders[fol_?StringQ, tag_] := Block[{folSel, done, cont},
	folSel = Select[FileNames[All, fol], (DirectoryQ[#] && (FileBaseName[#] === tag || StringTake[FileBaseName[#], 3] === "sub" || StringTake[FileBaseName[#], 3] === "ses")) &];
	done = Select[folSel, FileBaseName[#] === tag &];
	cont = Complement[folSel, done];
	Flatten[{done, If[cont =!= {}, SelectBidsFolders[cont, tag], Nothing]}]
]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSubjects*)


SyntaxInformation[SelectBidsSubjects] = {"ArgumentsPattern" -> {_}};

SelectBidsSubjects[fol_] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "sub") &]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSessions*)


SyntaxInformation[SelectBidsSessions] = {"ArgumentsPattern" -> {_}};

SelectBidsSessions[fol_?ListQ]:=Flatten[SelectBidsSessions/@fol]

SelectBidsSessions[fol_?StringQ] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "ses") &]


(* ::Subsubsection::Closed:: *)
(*BidsType*)


BidsType[type_?StringQ]:= bidsTypes[type] /. {Missing[___]->"miss"} 

BidsType[parts_?AssociationQ]:= bidsTypes[parts["Type"]] /. {Missing[___]->"miss"} 


(* ::Subsubsection::Closed:: *)
(*BidsValue*)


BidsValue[parts_,val_?ListQ]:=Flatten[BidsValue[parts,#]&/@val]

BidsValue[parts_,val_?StringQ]:=parts[val] /. {Missing[___]->""} 


(* ::Subsubsection::Closed:: *)
(*BidsString*)


BidsString[parts_, val_?ListQ]:=BidsString[parts,#]&/@val

BidsString[parts_, val_?StringQ]:=Block[{str},
	str = BidsValue[parts, val];
	If[str==="", "", val<>"-"<>str]
]


(* ::Subsection::Closed:: *)
(*ViewConfig*)


ViewConfig[folder_?StringQ]:=ViewConfig[GetConfig[folder]]

ViewConfig[config_?AssociationQ]:=TabView[Join[
	{"folders"->Column[config["folders"]/@{"dicomData","rawData","derivedData","mergeData"}]},
	({#["Type"], #["Suffix"]}->Column[Normal[#]])&/@CheckDataDiscription[config["dataSets"], "Process"]]
]


(* ::Subsection::Closed:: *)
(*CheckConfig*)


CheckConfig[infol_?StringQ, outfol_?StringQ]:=CheckConfig[infol, outfol, ""]

CheckConfig[infol_?StringQ, outfol_?StringQ, confin_]:=Block[{conf, nam},
	nam = GenerateBidsName[PartitionBidsFolderName[outfol][[-1]]];
	conf = Quiet@GetConfig[infol, nam];
	(*Print[FileNameJoin[{outfol, nam<>"_config.json"}]];*) 
	If[conf =!= $Failed,
		Export[FileNameJoin[{outfol, nam<>"_config.json"}], conf];
		{True, conf}, 
		{False, confin}
	]
]


(* ::Subsection::Closed:: *)
(*GetConfig*)


GetConfig[folder_?StringQ]:=GetConfig[folder, ""]

GetConfig[folder_?StringQ, nam_?StringQ]:=Block[{file},
	If[DirectoryQ[folder],
		(*normal config*)
		file = FileNameJoin[{folder,"config.json"}];
		If[FileExistsQ[file],
			Import[file, "RawJSON"],
			(*subject name config*)
			file = FileNameJoin[{folder, nam<>"_config.json"}];
			If[FileExistsQ[file],
				Import[file, "RawJSON"],
				Message[GetConfig::conf];
				Return[$Failed]
			]
		]
	]
]


(* ::Subsection::Closed:: *)
(*BidsDcmToNii*)


(* ::Subsubsection::Closed:: *)
(*BidsDcmToNii*)


Options[BidsDcmToNii]={BidsIncludeSession->True, SelectSubjects->All}

SyntaxInformation[BidsDcmToNii] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

BidsDcmToNii[folder_?StringQ, opts:OptionsPattern[]]:=BidsDcmToNii[folder, GetConfig[folder], opts];

BidsDcmToNii[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	dir = Directory[];
	SetDirectory[folder];
	BidsDcmToNii[
		config["folders"]["dicomData"],(*the input folder of the dcm data*)
		config["folders"]["rawData"],(*the output folder for converstion*)
		"",
		opts
	];
	SetDirectory[dir];
]

BidsDcmToNii[inFol_?StringQ, outFol_?StringQ, datDisIn_, ops:OptionsPattern[]]:=BidsFolderLoop[inFol, outFol, datDisIn, Method->"Dicom", ops]

(* ::Subsubsection::Closed:: *)
(*BidsDcmToNiiI*)


BidsDcmToNiiI[fol_, outI_, logFile_]:=Block[{out},
	(*define the outfolder*)
	out = FileNameJoin[{outI, "raw"}];
	(*----*)AddToLog[{"Output folder: ", out},1];
	Quiet[CreateDirectory[out]];
	
	(*perform the conversions only when output folder is empty*)
	If[EmptyDirectoryQ[out],
		(*perform conversion*)			
		(*----*)AddToLog["Starting the conversion", 1, True];
		DcmToNii[FileNameJoin[{Directory[],#}]&/@{fol,out}, MonitorCalc->False];
		(*----*)AddToLog["Folder was converted", 1],
		(*----*)AddToLog["Folder was skipped since output folder already exists", 1];
	];

	(*export the log after each name*)
	ExportLog[logFile];
]


(* ::Subsection:: *)
(*BidsSupport*)


(* ::Subsubsection::Closed:: *)
(*SubNameToBids*)


Options[SubNameToBids] = {BidsIncludeSession -> True};

SubNameToBids[nameIn_?ListQ, met_, opts : OptionsPattern[]] := SubNameToBids[#, met, opts] & /@ nameIn

SubNameToBids[nameIn_?StringQ, met_, OptionsPattern[]] := Block[{ass, keys, name, ses},
	(*get the names*)
	ass = Switch[met, "Sub", PartitionBidsName, "Dicom", PartitionBidsName[FileNameTake[#, {2, -1}]] &, _, PartitionBidsFolderName[#][[-1]] &]@nameIn;
	keys = Keys[ass];
	
	(*if bids take sub key else assume first suf is name*)
	name = "sub" -> If[MemberQ[keys, "sub"], ass["sub"], First[ass["suf"]]];
	
	(*if bids take ses key else assume last suf is session*)
	ses = "ses" -> If[MemberQ[keys, "ses"],
		(*session is present take session*)
		ass["ses"],
		(*more than one suf last is session*)
		If[Length[ass["suf"]] > 1, Last[ass["suf"]],
			(*no session,see if need to be forced*)
			If[OptionValue[BidsIncludeSession], "001", ""]]];
	Association[{name, ses, "suf" -> {}}]
]


(* ::Subsubsection::Closed:: *)
(*BidsFolderLoop*)


Options[BidsFolderLoop] = {DeleteAfterConversion->True, SelectSubjects->All, Method->"Convert", VersionCheck->False};

SyntaxInformation[BidsFolderLoop] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

BidsFolderLoop[inFol_?StringQ, datDis_, ops:OptionsPattern[]]:=BidsFolderLoop[inFol, inFol, datDis, ops]

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, datDisIn_, ops:OptionsPattern[]]:=Block[{
		met, datType, fols, subs, logFile, ass, nam, filesSl, jsons, files, nTyp, pat, rfol, cc, out, datDis
	},
	(*see which method*)
	met = OptionValue[Method];

	(*select the subjects to be processed*)
	subs = OptionValue[SelectSubjects];
	(*get all folders that can be processed*)
	fols = If[met==="Dicom",
		ResteLog[];
		Select[FileNames[All, inFol], DirectoryQ],
		SelectBidsSessions[SelectBidsSubjects[inFol]]	
	];
	subs = If[subs===All||subs==="All", fols, Select[fols, MemberQ[SubNameToBids[subs, "Sub"], SubNameToBids[#, met]]&]];
	
	(*open log*)
	ShowLog[];
	logFile="";

	(*loop over the subjects*)
	Table[
		(*get the bidsname*)
		ass = SubNameToBids[fol, met];
		nam = GenerateBidsName[ass];
		out = GenerateBidsFolderName[outFol, ass];
		
		(*check for custom config*)
		{cc, datDis} = CheckConfig[fol, out, datDisIn];
		
		(*convert the nameType to valid input, will always be a list of associations*)
		datType = CheckDataDiscription[datDis, met];

		(*start method specific logging*)
		Switch[met,
			(*BidsDcmToNii*)
			"Dicom",
			If[logFile==="", logFile = FileNameJoin[{outFol, "DcmToNii_"<>StringReplace[DateString[{"Day", "Month", "YearShort", "-", "Time"}],":"->""]<>".log"}]];
			(*----*)AddToLog[{"Starting dcm to nii conversion for directory: ", fol}, True, 0];
			(*----*)If[cc, AddToLog["**********   -----   Using custom config   -----   **********", 0]];
			(*----*)AddToLog["Using Chris Rorden's dcm2niix.exe (https://github.com/rordenlab/dcm2niix)", 1];
			,
			(*MuscleBidsConvert*)
			"Convert", 
			logFile = FileNameJoin[{fol, nam<>"_BIDSConvert.log"}];
			ImportLog[logFile];
			(*----*)AddToLog[{"Starting bids conversion for directory: ", fol}, True, 0];
			(*----*)If[cc, AddToLog["**********   -----   Using custom config   -----   **********", 0]];
			(*----*)AddToLog["Perform conversion for: ",1];
			,
			(*MuscleBidsProcess*)
			"Process", 
			logFile = FileNameJoin[{out, nam<>"_BIDSProcess.log"}];
			ImportLog[logFile];
			(*----*)AddToLog[{"Starting bids processing for directory: ", fol}, True, 0];
			(*----*)If[cc, AddToLog["**********   -----   Using custom config   -----   **********", 0]];
			,
			(*MuscleBidsMerge*)
			"Merge",
			logFile = FileNameJoin[{out, nam<>"_BIDSMerge.log"}];
			ImportLog[logFile];
			(*----*)AddToLog[{"Starting bids merging for directory: ", fol}, True, 0];
			(*----*)If[cc, AddToLog["********** Using custom config **********", 0]];
		];

		(*The actual process loops*)
		If[met==="Dicom",
			(*perform dicom nii conversions*)
			BidsDcmToNiiI[fol, out, logFile];
			,
			(*loop over the datType for other methods*)
			Table[
				(*check if datType is valid*)
				If[KeyExistsQ[type, $Failed],
					(*----*)AddToLog[dataToLog@type, 2, True];
					(*----*)AddToLog["Skipping", 3],
					(*if valid perform conversion*)
					(*----*)AddToLog[dataToLog@type, 2, True];
					rfol = SelectBidsFolders[fol, type["InFolder"]];
					
					(*method specific scripts: loop over all inFolders in subject folder*)
					Table[
						Switch[met,
							"Convert", (*MuscleBidsConvert*)
							MuscleBidsConvertI[foli, type, logFile, OptionValue[DeleteAfterConversion]],
							"Process", (*MuscleBidsProcess*)
							MuscleBidsProcessI[foli, outFol, type, logFile, OptionValue[VersionCheck]],
							"Merge", (*MuscleBidsMerge*)
							MuscleBidsMergeI[foli, outFol, type, datType, logFile, OptionValue[VersionCheck]]
						];
						ExportLog[logFile];				
					(*Close sub folders loop*)
					, {foli, rfol}];		
				];
				
				ExportLog[logFile];	
			(*close datatype loop*)
			, {type, datType}];
		(*close dicom if*)
		];

		(*export the log files*)
		ExportLog[logFile, True];

	(*close subject loop*)
	, {fol, subs}];
] 


(* ::Subsubsection::Closed:: *)
(*CheckDataDiscription*)


SyntaxInformation[CheckDataDiscription] = {"ArgumentsPattern" -> {_, _}};

CheckDataDiscription[dis:{_Association..}, met_]:=Flatten[CheckDataDiscription[Normal[#], met]&/@dis]

CheckDataDiscription[dis:{_List..}, met_]:= Flatten[CheckDataDiscription[#, met]&/@dis]

CheckDataDiscription[dis:{_Rule..}, met_]:=Block[{ass, key, man, cls, typ, fail},
	(*Get the data discription keys*)
	ass = Association[dis];
	key = Keys[ass];
	
	(*fail output*)
	fail = Association[$Failed->ToString[Normal[ass]]];
	
	(*Check if manditory keys are present*)
	man = ContainsAll[key, Switch[met,
		"Convert", {"Label", "Type"},
		"Process", {"Type"},
		"Merge", {"Type", "Merging"}
	]];
	
	If[!man,
		Return[Message[CheckDataDiscription::man]; fail],
		
		(*Check if type is valid*)
		If[!MemberQ[Keys[bidsTypes], ass["Type"]], Message[CheckDataDiscription::type, ass["Type"]]];
		
		(*Check if class is present*)
		If[KeyExistsQ[ass, "Class"],
			(*if present add check class is valid*)
			If[!MemberQ[bidsClass, ass["Class"]], Return[Message[CheckDataDiscription::class,ass["Class"]]; fail]],
			(*add class if not present*)
			ass = Association[ass, "Class"->"Volume"]
		];
		
		(*check if labels match class*)
		cls = Switch[ass["Class"],
			"Volume", StringQ[ass[["Label"]]],
			"Stacks"|"Repetitions", ListQ[ass["Label"] && Length[ass]>1]
		];
		If[!cls, Return[Message[CheckDataDiscription::lab, ass["Class"], ass["Label"]]; fail]];
		
		(*check suffic, in and out folder*)
		If[!KeyExistsQ[ass, "Suffix"], ass = Association[ass, "Suffix"->""]];
		Switch[met,
			"Convert",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->"raw"]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];
			,
			"Process"|"Merge",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->BidsType[ass["Type"]]]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];			
		];
		
		(*add overlap if class is stacks*)
		If[ass["Class"]==="Stacks"&&!KeyExistsQ[ass["Merging"],"Overlap"], Message[CheckDataDiscription::stk]; ass = Association[ass, "Overlap"->0]];
		
		(*output the completed data discription*)
		{KeySort@ass}
	]
]


(* ::Subsection:: *)
(*MuscleBidsConvert*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvert*)


Options[MuscleBidsConvert] = {DeleteAfterConversion->True, SelectSubjects->All};

SyntaxInformation[MuscleBidsConvert] = {"ArgumentsPattern" -> {_, _., OptionsPattern[]}};

MuscleBidsConvert[folder_?StringQ, opts:OptionsPattern[]]:=MuscleBidsConvert[folder, GetConfig[folder], opts];

MuscleBidsConvert[folder_, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir}, 
	dir = Directory[];
	SetDirectory[folder];(*SetDirectory[config["folders"]["root"]];*)
	MuscleBidsConvert[
		config["folders"]["rawData"],(*the input folder for the data*)
		config["dataSets"],(*what to process*)
		opts];
	SetDirectory[dir];
]
		

MuscleBidsConvert[niiFol_?StringQ, datDis_, opts:OptionsPattern[]]:= BidsFolderLoop[niiFol, datDis, Method->"Convert", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvertI*)


MuscleBidsConvertI[foli_, datType_, logFile_, del_]:=Block[{
		type, fol, parts, files, json, infoExtra, pos, posi, info, data, vox, grad, val, sufd, outFile
	},

	(*see if one label or session|repetion*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	
	(*-----*)AddToLog[{"Converting", ToString[Length[datType["Label"]]], datType["Class"]}, 2, True];
	(*-----*)AddToLog[StringJoin@@Riffle[datType["Label"],", "], 3];
	
	(*loop over stac names*)
	Table[
		(*import the json belonging to name*)
		(*-----*)AddToLog[{"Converting", namei, "as", type,":"}, True, 3];
		files = FileNames["*"<>namei<>"*.json", foli];
		
		If[Length@files===0,
			(*no json files found*)
			(*-----*)AddToLog[{"No json files found with label ", namei , " skipping conversion"}, 4],
			
			(*if json files found import them*)
			json = ImportJSON/@files;
			
			(*see which data type is expected*)
			Switch[datType["Type"],
			
				(*-------------------------------------------*)
				(*-------- DIXON conversion script ----------*)
				(*-------------------------------------------*)
				"megre",
				
				(*loop over dixon data types*)
				Table[
					(*get the posisiton of the files needed*)
					pos = GetJSONPosition[json, {{"ProtocolName", namei}, {"ImageType", dixType}}, "EchoNumber"];
					
					(*-----*)AddToLog[{"Importing", Length[pos], "datasets with properties: ", {namei, dixType}}, 4];
					
					(*get the json and data*)
					info = MergeJSON[json[[pos]]];
					{data, vox} = Transpose[ImportNii[#]&/@ConvertExtension[files[[pos]], ".nii"]];
					data = Transpose[data];
					vox = First@vox;
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
					
					(*correct data for different types*)
					{data,sufd}=Switch[dixType,
						"Mixed",{1000.data/2047.,""},
						"Phase",{Pi (data-2047.)/2047,"ph"},
						"Real",{1000.(data-2047.)/2047.,"real"},
						"Imaginary",{1000.(data-2047.)/2047.,"imag"}
					];
					
					(*make the additional manditory bids json values*)
					infoExtra=<|
						"ForthDimension"->"EchoTime",
						"DataClass"->datType["Class"],
						If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
						If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
						If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
					|>;
					
					(*export to the correct folder*)
					outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->Flatten@{datType["Suffix"], sufd}|>];
					(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
					ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
					Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
					
					(*Delete used files*)
					Quiet@If[del,
						DeleteFile[ConvertExtension[files[[pos]],".nii"]];
						DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
						DeleteFile[ConvertExtension[files[[pos]],".json"]]
					];
					
					(*export log after each type*)
					ExportLog[logFile]			
				(*Closeloop over dixon data types*)
				,{dixType, {"Mixed", "Phase", "Real", "Imaginary"}}],
				
				(*-------------------------------------------*)
				(*---------- DWI conversion script ----------*)
				(*-------------------------------------------*)
				"dwi",
				
				(*get the posisiton of the files needed*)
				pos = GetJSONPosition[json, {{"ProtocolName", namei}}];
				(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", namei}, 4];
				
				(*get the json and data*)
				info = json[[First@pos]];
				{data, grad, val, vox} = ImportNiiDiff[ConvertExtension[files[[First@pos]],".nii"], FlipBvec->False];
				(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
				
				(*make the additional manditory bids json values*)
				infoExtra=<|
					"ForthDimension"->"Diffusion",
					"DataClass"->datType["Class"],
					If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
					If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
					If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
				|>;
				
				(*export to the correct folder*)
				outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->{datType["Suffix"]}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
				ExportBval[val, ConvertExtension[outFile, ".bval"]];
				ExportBvec[grad, ConvertExtension[outFile, ".bvec"]];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
				Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
				
				Quiet@If[del,
					(*-----*)AddToLog[{"Deleting", Length[pos], type, "dataset with properties: ", namei}, 4];
					DeleteFile[ConvertExtension[files[[pos]],".nii"]];
					DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
					DeleteFile[ConvertExtension[files[[pos]],".json"]];
					DeleteFile[ConvertExtension[files[[pos]],".bval"]];
					DeleteFile[ConvertExtension[files[[pos]],".bvec"]];
				],
				
				(*-------------------------------------------*)
				(*----------- T2 conversion script ----------*)
				(*-------------------------------------------*)
				"mese",
				
				(*get the posisiton of the files needed*)
				pos = posi = GetJSONPosition[json, {{"ProtocolName", namei}}, "EchoTime"];
				(*select only echos*)
				info = MergeJSON[json[[pos]]];
				pos = pos[[;; info["EchoTrainLength"]]];
				(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", namei}, 4];
				
				(*get the json and data*)
				AssociateTo[info, "EchoNumber" -> Range@info["EchoTrainLength"]];
				{data, vox} = Transpose[ImportNii /@ ConvertExtension[files[[pos]],".nii"]];
				data = Transpose[data];
				vox = First@vox;
				(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
				
				(*make the additional manditory bids json values*)
				infoExtra=<|
					"ForthDimension"->"EchoTime",
					"DataClass"->datType["Class"],
					If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
					If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
					If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
				|>;
				
				(*export to the correct folder*)
				outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->{datType["Suffix"]}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
				Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
				
				(*Delete used files*)
				Quiet@If[del,
					(*-----*)AddToLog[{"Deleting", Length[posi], type, "datasets with properties: ", namei},4];
					DeleteFile[ConvertExtension[files[[posi]],".nii"]];
					DeleteFile[ConvertExtension[files[[posi]],".nii.gz"]];
					DeleteFile[ConvertExtension[files[[posi]],".json"]]
				],
				
				(*-------------------------------------------*)
				(*-------- Other processing script ----------*)
				(*-------------------------------------------*)
				_,
				Print["Unknow type for conversion"];
			
			(*Close Type switch*)
			];
		(*close file check*)	
		];
		(*export the log after each name*)
		ExportLog[logFile];
	(*close loop over stac names*)
	,{namei, datType["Label"]}];
] 


(* ::Subsubsection::Closed:: *)
(*GetStackName*)


GetStackName[class_, namei_]:=Switch[class,
	"Volume", "",
	"Stacks"|"Repetitions",
	Switch[class, "Stacks", "stk", "Repetitions", "rep"] -> StringReplace[namei,{"-"->"","_"->"","."->""}]
]


(* ::Subsection:: *)
(*MuscleBidsProcess*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcess*)


Options[MuscleBidsProcess] = {SelectSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsProcess] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsProcess[folder_?StringQ, opts:OptionsPattern[]]:=MuscleBidsProcess[folder, GetConfig[folder], opts];

MuscleBidsProcess[folder_, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir}, 
	dir = Directory[];
	SetDirectory[folder];(*SetDirectory[config["folders"]["root"]];*)
	MuscleBidsProcess[
		config["folders"]["rawData"],(*the input folder for the data*)
		config["folders"]["derivedData"],(*the output folder for processing*)
		config["dataSets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]

MuscleBidsProcess[niiFol_?StringQ, outFol_?StringQ, datDis_?ListQ, ops:OptionsPattern[]]:= BidsFolderLoop[niiFol, outFol, datDis, Method->"Process", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcessI*)


MuscleBidsProcessI[foli_, folo_, datType_, logFile_, verCheck_]:=Block[{
		con, fol, parts, type, files, sets, dfile, nfile, process, keys, dfiles, jfile, nfiles,
		outfile, json, echos, mag, ph, real, imag, dvox, magM, B0mask, ph0i, pos, e1, e2, phasediff, hz, b0i,
		t2stari, watfr, fatfr, wat, fat , inph, outph, b0, t2star, r2star, phi, itt, res, outTypes, preProc, 
		nfilep, resi, data, grad, val, diffvox, mask, den, sig, snr, snr0, reg, valU, mean, fiti, s0i, fri, 
		adci, pD, tens, s0, out, l1, l2, l3, md, fa, rd, t2vox, t2w, t2f, b1, n, angle, ex, ref, thk, 
		phii, phbpi, phbp, ta, filt
	},
	
	(*get the context for exporting*)
	con = Context[con];

	(*get the information needed for processing, e.g. session|repetion*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	process = datType["Process"];
	keys = {"EchoTime", "ForthDimension", "DataClass", "Stack", "OverLap", "SliceThickness", "SpacingBetweenSlices"};

	(*see what needs to be processed*)
	files = Flatten[FileNames["*"<>StringReplace[#, {"-"->"","_"->"","."->""}]<>"*.json", foli]& /@ datType["Label"]];
	sets = If[type==="megre",
		DeleteDuplicates[(ta = #;AssociateTo[ta, "suf"->{First[ta["suf"]]}])&/@PartitionBidsName[FileBaseName/@files]],
		DeleteDuplicates[PartitionBidsName[FileBaseName/@files]]];
	(*-----*)AddToLog[{"Found", ToString[Length[sets]], datType["Class"], "that will be processed:"}, 2];
	
	(*loop over sets*)
	Table[
		(*-----*)AddToLog[dataToLog@set,2 ];
		(*see which data type is expected*)
		Switch[type,
			
			"megre",
			(*-------------------------------------------*)
			(*-------- megre processing scripts ---------*)
			(*-------------------------------------------*)
	
			Switch[process["Method"],
				
				"Dixon",
				(*-------------------------------------------*)
				(*-------- Dixon processing scripts ---------*)
				(*-------------------------------------------*)
				
				(*input file names*)
				dfiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@{"", "ph", "real", "imag"};
				jfile = ConvertExtension[First@dfiles, ".json"];
				nfiles = ConvertExtension[dfiles, ".nii"];
				
				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];
		
				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[First@dfiles, 4];
					
					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,
						(*Check if needed nii Exist*)
						If[!AllTrue[nfiles, NiiFileExistQ],
							(*----*)AddToLog[{"Could not find all the ", First@dfiles}, 4],
							(*----*)AddToLog["Importing the data", 4];
	
							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							{{mag, ph, real, imag}, dvox} = Transpose[ImportNii/@nfiles];
							dvox = First@dvox;
							
							(*Apply background mask*)
							magM = NormalizeData[Mean@Transpose@mag];
							B0mask = Dilation[Mask[magM, 15, MaskSmoothing->True, MaskComponents->2, MaskClosing->2], 1];
							{mag, ph, real, imag} = MaskData[#,B0mask]&/@{mag,ph,real,imag};
							
							(*see if there are dixon flips*)
							(*{{mag, ph, real, imag}, pos} = FixDixonFlips[{mag, ph, real, imag}];
							(*-----*)If[pos=!={}, AddToLog[{"Found complex flips in volumes: ", pos}, 4]];*)
							pos = {};
							
							(*calculated field maps*)
							(*-----*)AddToLog[{"Starting field map calcualtion"}, 4];
							{{b0i, t2stari, phii, phbpi}, {e1, e2, n}} = DixonPhase[{real, imag}, echos];
							(*-----*)AddToLog[{"used echo ", ToString[e1], "(",1000echos[[e1]],"ms ) and", ToString[e2], "(", 1000 echos[[e2]], "ms )"}, 5];
							
							(*perform the IDEAL dixon fit*)
							(*-----*)AddToLog["Starting Dixon reconstruction",4];
							{{watfr, fatfr}, {wat, fat}, {inph, outph}, {{b0, phi, phbp}, {t2star, r2star}}, itt, res} = DixonReconstruct[{real, imag}, echos, {b0i, t2stari, phii, phbpi}, 
								DixonBipolar->True, DixonInitial->True, 
								DixonClipFraction->True, DixonAmplitudes -> {15.5, 3.0, 0.75}];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:",4];
							(*----*)AddToLog[outfile,5];
							outTypes = {"real", "imag", "mag", "ph", "b0i", "phii", "t2stari", "phbpi", "b0", "phi", "phbp", "t2star", "r2star", 
								"inph", "outph", "wat", "fat", "watfr", "fatfr", "itt", "res"};
							ExportNii[ToExpression[con<>#], dvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
							
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes"->echos, "DixonFlips" -> pos, "DixonBipolar" -> True, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];
						]
					]
				(*close dixon processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*-------------- Unknown megre --------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			
			(*close megre processing*)
			],
			
			
			"dwi",
			(*-------------------------------------------*)
			(*--------- dwi processing script -----------*)
			(*-------------------------------------------*)
			
			
			(*input file names*)
			dfile = GenerateBidsFileName[fol, set];
			jfile = ConvertExtension[dfile,".json"];
			nfile = ConvertExtension[dfile,".nii"];
						
			(*ouput file names*)
			outfile = GenerateBidsFileName[folo, set];
			
			(*-------------------------------------------*)
			(*------- dwi pre -processing script --------*)
			(*-------------------------------------------*)
			
			(*check if pre-processin is already done*)
			preProc = False;
			If[CheckFile[outfile<>"_prep", "done", verCheck],
				(*if checkfile has label done and version is recent skip*)
				(*----*)AddToLog["Pre-processing already done for: ", True, 3];
				(*----*)AddToLog[outfile, 4],
				(*----*)AddToLog["Starting pre-processing for data:", 3, True];
				(*----*)AddToLog[dfile, 4];
				
				If[!FileExistsQ[jfile],
					(*----*)AddToLog["Could not find the needed JSON file",4],
					(*Check if needed nii Exist*)
					If[!(NiiFileExistQ[nfile]&&FileExistsQ[ConvertExtension[nfile,".bval"]]&&FileExistsQ[ConvertExtension[nfile,".bvec"]]),
						(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"},4],
						(*----*)AddToLog["Importing the data", 4];

						(*import the data*)
						json = ImportJSON[jfile];
						{data, grad, val, diffvox} = ImportNiiDiff[nfile, FlipBvec->False];
						{data, grad, val} = SortDiffusionData[NormalizeData[data], grad, val];
						
						(*Denoise*)
						(*-----*)AddToLog["Starting dwi denoising", 4];
						mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing->True, MaskComponents->2, MaskDilation->1];
						{den, sig} = PCADeNoise[data, mask, PCAOutput->False, PCATollerance->0, PCAKernel->5];
						
						(*calculate SNR*)
						snr = SNRCalc[den, sig];
						snr0 = Mean@Transpose@First@SelectBvalueData[{snr, val}, {0, 2}];
						
						(*register data - each leg seperate*)
						(*-----*)AddToLog["Starting dwi motion and eddy correction", 4];
						reg = RegisterDiffusionDataSplit[{den, mask, diffvox}, Iterations->300, NumberSamples->5000, PrintTempDirectory->False];

						(*anisotropic filtering*)
						(*-----*)AddToLog["Starting anisotrpic data smooting", 4];
						filt = AnisoFilterData[reg, diffvox];
						
						(*export all the calculated data*)
						(*----*)AddToLog["Exporting the calculated data to:",4];
						(*----*)AddToLog[outfile, 5];
						outTypes = {"den", "reg", "sig", "snr0", "snr", "filt"};
						ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
						ExportBval[val, ConvertExtension[outfile <> "_"<>#, ".bval"]]&/@{"reg","filt"};
						ExportBvec[grad, ConvertExtension[outfile <> "_"<>#, ".bvec"]]&/@{"reg","filt"};
						
						(*export the checkfile*)
						MakeCheckFile[outfile<>"_prep", Sort@Join[
							{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
							ExtractFromJSON[keys]
						]];
						(*----*)AddToLog["Finished pre-processing", 3, True];
						
						(*Set preproc true, overrules checkfile for processing*)
						preProc = True;
					]
				]
			(*close preprocessing*)
			];
			
			Switch[process["Method"],
				
				"DTI",
				(*-------------------------------------------*)
				(*---------- dwi processing script ----------*)
				(*-------------------------------------------*)

				(*input file for processing*)
				nfilep = ConvertExtension[GenerateBidsFileName[folo, <|set, "suf"->{datType["Suffix"], "filt"}|>],".nii"];

				(*check if processin is already done, redo is prep is done*)					
				If[If[!preProc, CheckFile[outfile, "done", verCheck], False],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[nfilep, 4];				
					
					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,
						
						(*Check if needed nii Exist*)
						If[!(NiiFileExistQ[nfilep]&&FileExistsQ[ConvertExtension[nfilep,".bval"]]&&FileExistsQ[ConvertExtension[nfilep,".bvec"]]),
							(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"}, 4],
							(*----*)AddToLog["Importing the data", 4];
	
							(*import the data*)
							json = ImportJSON[jfile];
							{data, grad, val, diffvox} = ImportNiiDiff[nfilep, FlipBvec->False];
							mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing->True, MaskComponents->2, MaskClosing->2];
							data = MaskData[data, mask];
							(*get bvalues and mean data*)
							{mean, valU} = MeanBvalueSignal[data, val];
							
							(*initialize IVIM fit*)
							(*-----*)AddToLog["Starting ivim calculation", 4];
							fiti = IVIMCalc[MeanSignal[mean], valU, {1,.05,.003,.015}, IVIMFixed->True];
							(*perform IVIM correction*)
							{s0i, fri, adci, pD}= Quiet@IVIMCalc[mean, valU, fiti, IVIMConstrained->False, Parallelize->True, MonitorIVIMCalc->False, IVIMFixed->True];
							fri = Clip[fri, {0,1}, {0,1}];
							adci = 1000 adci;
							resi = Quiet@IVIMResiduals[mean, valU, {s0i, fri, adci, pD}];
							
							(*calculate tensor from corrected data*)
							(*-----*)AddToLog["Starting tensor calculation", 4];
							data = First@IVIMCorrectData[data, {s0i, fri, pD}, val, FilterMaps->False];
							{tens, s0, out, res} = Quiet@TensorCalc[data, grad, val, FullOutput->True, Method->"iWLLS", RobustFit->True, Parallelize->True, MonitorCalc->False];
							out = Total@Transpose@out;
							(*calculate tensor parameters*)
							{l1, l2, l3, md, fa} = ParameterCalc[tens];
							rd = Mean[{l2, l3}];
							tens = Transpose[tens];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "mean", "tens", "res", "out", "s0", 
								"l1", "l2", "l3", "md",	"fa", "rd", "adci", "fri", "s0i"};
							ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];				
						]
					]
				(*close dti processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*--------------- Unknown dti ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],
			
			"mese",
			(*-------------------------------------------*)
			(*-------- mese processing scripts ----------*)
			(*-------------------------------------------*)
			
			Switch[process["Method"],				
				
				"EPGT2",
				(*-------------------------------------------*)
				(*---------- EPG processing script ----------*)
				(*-------------------------------------------*)

				(*input file names*)
				dfile = GenerateBidsFileName[fol, set];
				jfile = ConvertExtension[dfile,".json"];
				nfile = ConvertExtension[dfile,".nii"];
				
				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[dfile, 4];
					
					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog[{"Could not find the needed JSON file of", jfile}, 4];,
						(*Check if needed nii Exist*)
						If[!NiiFileExistQ[nfile],
							(*----*)AddToLog[{"Could not find the data of", dfile}, 4],
							(*----*)AddToLog["Importing the data", 4];
							
							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							{data, t2vox} = ImportNii[nfile];
							
							(*mask the background*)		
							mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2];
							data = MaskData[data, mask];
							
							(*determine the pulse profiles*)
							(*-----*)AddToLog["Calculating the slice profiles", 4];							
							{ex, ref} = datType["Process"]["Settings"];
							thk = 2 json["SliceThickness"];
							angle = GetPulseProfile[ex, ref, SliceRange -> thk, SliceRangeSamples -> thk][[1;;2]];
							
							(*caculate the water t2 map*)
							(*-----*)AddToLog["Starting EPG T2 calculation", 4];
							{{t2w, t2f, b1}, {wat, fat, fatfr}, res} = EPGT2Fit[data, 1000 echos, angle, 
								MonitorCalc -> False, DictT2IncludeWater -> True, DictT2fValue -> 200, DictT2fRange -> {150, 250, 5}, 
								DictB1Range -> {0.5, 1.4, 0.02}, DictT2Range -> {15, 45, 0.2}
							];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "t2w", "t2f", "b1", "wat", "fat", "fatfr", "res"};
							ExportNii[ToExpression[con<>#], t2vox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes" -> echos, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];
						]
					]
				(*close t2 processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*--------------- Unknown mese ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],
			(*-------------------------------------------*)
			(*------------------ Other ------------------*)
			(*-------------------------------------------*)
			_,
			Print["Unknow type for conversion"];
		
		(*Close Type switch*)
		];
		
		(*export the log after each set*)
		ExportLog[logFile]
		
	(*close loop over sets*)
	, {set, sets}]
]


(* ::Subsection:: *)
(*MuscleBidsMerge*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMerge*)


Options[MuscleBidsMerge] = {SelectSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsMerge] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsMerge[folder_?StringQ, opts:OptionsPattern[]]:=MuscleBidsMerge[folder, GetConfig[folder], opts];

MuscleBidsMerge[folder_, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir}, 
	dir = Directory[];
	SetDirectory[folder];(*SetDirectory[config["folders"]["root"]];*)
	MuscleBidsMerge[
		config["folders"]["derivedData"],(*the input folder for the data*)
		config["folders"]["mergeData"],(*the output folder for merging*)
		config["dataSets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]

MuscleBidsMerge[datFol_?StringQ, merFol_?StringQ, datDis_?ListQ, ops:OptionsPattern[]]:= BidsFolderLoop[datFol, merFol, datDis, Method->"Merge", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMergeI*)


MuscleBidsMergeI[foli_, folo_, datType_, allType_, logFile_, verCheck_]:=Block[{
		nonQuant, motion, reverse, fol, parts, merge, outfile, tarType, tarSuf, tarCon, tarFile, movType, movCon, n,
		movs, movStacs, tarStacs, overT, overM, targets, movings, mov, nStac, nCheck, nSet, target, voxt, moving, 
		voxm, files, im, func, reg, mskm, mskt, vox, sameType,
		multDim, movsA, movsMD, movingsA, movingsMD, movingA, movingMD, leng, lengMD
	},

	(*muscle bids that are non quantitative of multi dimensional*)
	nonQuant = {"inph", "outph", "wat", "fat", "s0"};
	multDim = {"tens"};

	(*need to become options in the future*)
	motion = True;
	reverse = False;

	(*get the outfile names*)
	{fol, parts} = PartitionBidsFolderName[foli];
	merge = datType["Merging"];
	outfile = GenerateBidsFileName[folo, <|parts, "suf"->datType["Suffix"], "Type"->datType["Type"]|>];

	(*get the settings for the target data*)
	{tarType, tarSuf, tarCon} = merge["Target"];
	tarFile = GenerateBidsFileName[folo, <|parts, "suf"->{tarSuf, tarCon}, "Type"->tarType|>]<>".nii";
	tarStacs = StringReplace[#, {"-" -> "", "_" -> "", "." -> ""}] & /@ First[Select[allType, #["InFolder"] === tarSuf &]]["Label"];

	(*check if moving is the same type as target*)
	sameType = tarType === datType["Type"] && tarSuf === datType["Suffix"];

	(*get the settings for the moving data*)
	movType = datType["InFolder"];
	movCon = merge["Moving"];
	movStacs = StringReplace[#, {"-"->"","_"->"","."->""}]&/@datType["Label"];
	movs = Select[merge["Process"], ! MemberQ[multDim, #] &];
	movsMD = Select[merge["Process"], MemberQ[multDim, #] &];
	movsA = Join[movs, movsMD];
	
	(*get the settings for the merging*) 
	overT = merge["Overlap"];
	{overT, overM} = If[IntegerQ[overT], {overT, overT}, overT];
	
	(*start the merging, if checkfile has label done and version is recent skip*)
	If[CheckFile[outfile, "done", verCheck],
		(*-----*)AddToLog[{"Processing already done for:"}, 3];
		(*-----*)AddToLog[{StringJoin@Riffle[movsA,", "]}, 4];,
		(*-----*)AddToLog[{"The types that will be merged are: "}, 3];
		(*-----*)AddToLog[{StringJoin@Riffle[movsA,", "]}, 4];
		
		(*get all the moving and target data file names*)
		targets = Flatten[FileNames["*"<>#<>"*"<>tarSuf<>"*"<>tarCon<>".nii.gz", FileNameJoin[{DirectoryName[foli], tarSuf}]]&/@tarStacs];
		movings = (mov = #; Flatten[FileNames["*"<>#<>"*"<>mov<>".nii.gz", foli]& /@movStacs])& /@movs;
		movingsMD = (mov = #; Flatten[FileNames["*"<>#<>"*"<>mov<>".nii.gz", foli]& /@movStacs])& /@movsMD;
		movingsA = Join[movings, movingsMD];

		(*check if number of stacks are consistant*)
		nStac = Length@movStacs;
		nSet = Length[movsA];
		nCheck = AllTrue[n=Join[{Length[targets]}, Length/@movingsA], #===nStac&];

		If[!nCheck,
			(*-----*)AddToLog[{"Not all types have the same number of stacs:", StringJoin@Riffle[ToString/@n,", "]}, 3],
			(*-----*)AddToLog[{"Start joining ", nStac, "stacs for", nSet, "dataypes"}, 3];
			
			(*import the Target data, import merged target if it exists else merge it*)
			(*-----*)AddToLog[{"Importing and processing the target data"}, 4];
			(*if target is same type as moving always perform joinsets, never load from disk*)
			If[NiiFileExistQ[tarFile] && !sameType,
				{target, voxt} = ImportNii[tarFile];
				(*-----*)AddToLog[{"Splitting the primary datatype that already existed"}, 4];
				If[nStac=!=1,target = SplitSets[target, nStac, overT, ReverseSets->reverse]];
				,

				{target, vox} = Transpose[ImportNii/@targets];
				voxt = First@vox;
				(*-----*)AddToLog[{"Joining the primary datatype",If[motion,"with","without"],"motion correction"}, 4];
				If[nStac=!=1,
					target = JoinSets[target, overT, voxt, ReverseSets->reverse, MotionCorrectSets->motion, 
						NormalizeSets->True, NormalizeOverlap->True, MonitorCalc->False];
					target = SplitSets[target, nStac, overT, ReverseSets->reverse];
				];
			];
			
			(*-----*)AddToLog[{"Importing and processing the moving data"}, 4];
			(*import the moving data, only import multi dim if present*)
			{moving, vox} = Transpose[(files=#;Transpose[ImportNii[#]&/@files])& /@movings];
			leng = Length[movs];
			voxm = First@First@vox;
			movingMD = If[movingsMD=!={},
				{movingMD, vox} = Transpose[(files=#;Transpose[ImportNii[#]&/@files])& /@movingsMD];
				lengMD = Length /@ movingMD[[All, 1, 1]];
				Flatten[movingMD, {1, 4}],
				{}];
			movingA = Join[moving, movingMD];

			(*perform motion correction after target merging*)
			(*If motion correction for joning is False and target is of same type no need for motion correction*)
			If[!(!motion&&sameType), 
				(*-----*)AddToLog[{"Performing the registration for the all the datasets"}, 4];
				im = First@First@Position[movs, movCon];
				movingA = Table[
					(*make masks*)
					mskm = DilateMask[Mask[NormalizeData[moving[[im, i]]], 10], 5];
					mskt = DilateMask[Mask[NormalizeData[target[[i]]], 10], 5];
					
					(*only split if not first stack*)
					(*move the target from anatomical to native space*)
					func = If[i===If[reverse, nStac, 1], RegisterData, RegisterDataSplit];
					reg = ToPackedArray@N@Chop@func[{moving[[im,i]], mskm, voxm}, {target[[i]],voxt}, 
						Iterations->300, PrintTempDirectory->False, BsplineSpacing->20 voxm, InterpolationOrderReg->1, NumberSamples -> 10000,
						MethodReg->Switch[movType, "dix", "rigid", "quant", {"rigid","affine"}, _, {"rigid","affine","bspline"}]];
						
					(*register back the target from native space to anatomy and tranfrom the rest*)
					func = If[i===If[reverse, nStac, 1], RegisterDataTransform, RegisterDataTransformSplit];
					ToPackedArray@N@Chop@Last@func[{target[[i]], mskt, voxt}, {reg, voxm}, {Transpose[movingA[[All,i]]], voxm},
						Iterations->300,  BsplineSpacing->10 voxm, InterpolationOrderReg->1, NumberSamples -> 10000, 
						PrintTempDirectory->False, DeleteTempDirectory->False,
						MethodReg->Switch[movType, "dix", "rigid", "quant", {"rigid","affine"}, _, {"rigid","affine","bspline"}]]
				,{i, 1, nStac}];
				
				(*extract all parameters after registration*)
				movingA = Transpose[movingA, {2,3,1,4,5}];
			];(*clolse motion moving*)
			
			(*join the moving types*)
			(*-----*)AddToLog[{"Joining the data"}, 4];
			movsA = Flatten[{movs, ConstantArray[#[[1]], #[[2]]] & /@ Thread[{movsMD, lengMD}]}];
			movingA = JoinSets[movingA[[#]], overT, voxm, MonitorCalc->False, MotionCorrectSets->False, 
					ReverseSets->reverse, NormalizeSets->MemberQ[nonQuant, movsA[[#]]], NormalizeOverlap->MemberQ[nonQuant, movsA[[#]]]
				]&/@Range[Length[movsA]];
			
			(*split in single dim and multi dim*)
			If[movingMD =!= {},
				moving = movingA[[1;;leng]];
				movingMD = movingA[[leng+1;;]];
				movingMD = Transpose[movingMD[[#[[1]];;#[[2]]]]] & /@ ({1, 0} + # & /@ Partition[Prepend[Accumulate[lengMD], 0], 2, 1]);
				movingA = Join[moving, movingMD];
			];
			
			(*export the joined data*)
			(*----*)AddToLog["Exporting the calculated data to:", 4];
			(*----*)AddToLog[outfile, 5];
			movsA = Join[movs, movsMD];
			ExportNii[movingA[[#]], voxt, outfile<>"_"<>movsA[[#]]<>".nii"] &/@ Range[nSet];
			
			(*make the checkfile*)
			MakeCheckFile[outfile, Sort@Join[{"Check"->"done"}, Normal@datType]];
			(*----*)AddToLog["Finished merging", 3, True];
		
		](*close ncheck*)
	](*close checkfile*)
]


(* ::Subsection:: *)
(*JSON*)


(* ::Subsubsection::Closed:: *)
(*ImportJSON*)


ImportJSON[file_]:=Import[file,"RawJSON"]


(* ::Subsubsection::Closed:: *)
(*GetJSONPosition*)


GetJSONPosition[json_, selection_]:=GetJSONPosition[json, selection, ""]

GetJSONPosition[json_, selection_, sort_]:=Block[{seli, self, list, key, val, inds, pos},
	(*selection functions*)
	seli = StringReplace[ToLowerCase[Last[Flatten[{#1 /. #3}]]], "wip " -> ""] === ToLowerCase[#2] &;
	self = (
		list=#1;
		key=#2[[1]]; 
		val=#2[[2]]; 
		Select[list, seli[key,val,json[[#]]]&]
	)&;
	
	(*get the file positions*)
	pos = Fold[self, Range[Length[json]], selection];
	(*sort positions if needed*)
	If[sort==="", pos, pos[[Ordering[sort /. json[[pos]]]]]]
]


(* ::Subsubsection::Closed:: *)
(*MergeJSON*)


MergeJSON[json:{_?AssociationQ..}]:=Block[{keys},
	keys=DeleteDuplicates[Flatten[Keys /@ json]];
	
	Association[If[#[[2]]==={},Nothing,#]& /@ Thread[
			keys->(
				If[Length[#]===1,First@#,#]& /@ (
					(DeleteDuplicates /@ Transpose[(# /@ keys)& /@ json]) /. Missing[___]->Nothing
				)
			)
		]
	]
]


(* ::Subsubsection::Closed:: *)
(*ExtractFromJSON*)


ExtractFromJSON[keys_] := ((# -> json[#]) & /@ keys) /. {(_ -> Missing[___]) -> Nothing};


(* ::Subsubsection::Closed:: *)
(*AddToJson*)


AddToJson[json_, add_]:=MergeJSON[{json,
	Switch[add,
		"QMRITools",<|"ConversionSoftware"->"QMRITools.com", "ConversionSoftwareVersion"->QMRITools`$InstalledVersion|>,
		_,add]}
]


(* ::Section:: *)
(*End Package*)


End[]

EndPackage[]
